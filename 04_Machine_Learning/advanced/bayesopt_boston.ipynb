{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Optimization Example: Boston Housing Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Resources\n",
    " - [Scikit-Learn](http://scikit-learn.org/)\n",
    " - [Scikit-Optimize](https://github.com/scikit-optimize/scikit-optimize) \n",
    " - [GPyOpt](https://gpyopt.readthedocs.io/en/latest/)\n",
    " - [GPyOpt GitHub](https://github.com/SheffieldML/GPyOpt)\n",
    " - [fmfn/BayesianOptimization](https://github.com/fmfn/BayesianOptimization)\n",
    " - [Taking the Human Out of the Loop: A Review of Bayesian Optimization](https://ieeexplore.ieee.org/document/7352306/)\n",
    " - [Practical Bayesian Optimization of Machine Learning Algorithms](https://arxiv.org/abs/1206.2944)\n",
    " - [Evaluating Hyperparameter Optimization Strategies](https://blog.sigopt.com/posts/evaluating-hyperparameter-optimization-strategies)\n",
    " - [A Tutorial on Bayesian Optimization of Expensive Cost Functions, with Application to Active User Modeling and Hierarchial Reinforcement Learning ](https://arxiv.org/abs/1012.2599)\n",
    " \n",
    "## Introduction\n",
    "Bayesian Optimization is a strategy for global optimization of black-box functions with the goal of finding a min/max of a function f(x) bounded by X. The Bayesian optimization will construct a probabilistic model for f(x) to exploit in order to determine where in X to evaluate the function next. It performs this determination using the information from previous evaluations of f(x).\n",
    "\n",
    "## General Theory\n",
    "#### Objective:\n",
    "Find global maximizer or minimizer of a function $f$(x)\n",
    "$$\\textbf{x}^{*} = \\text{arg} \\max_{\\textbf{x} \\in \\chi } f(\\textbf{x})$$\n",
    "$\\chi$ is the space of interest and can be categorical, conditional, or both\n",
    "\n",
    "#### Strategy \n",
    "- Unknown objective function \n",
    "- Treat as a random function \n",
    "- Place prior over it\n",
    "- Prior captures belief about function\n",
    "- Gather information and update the prior with posterior \n",
    "- Determine next query point based on priors\n",
    "\n",
    "![](https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/5/7360840/7352306/shahr1-2494218-large.gif)[A Tutorial on Bayesian Optimization of Expensive Cost Functions, with Application to Active User Modeling and Hierarchial Reinforcement Learning ](https://arxiv.org/abs/1012.2599)\n",
    "\n",
    "\n",
    "## Summarize\n",
    "- Finds min/max with relatively few evaluations\n",
    "- Cost of more computation to determine next point to try\n",
    "- Good for expensive functions such as ML\n",
    "\n",
    "## What can $f$ be?\n",
    "Bayesian Optimization is best used for costly functions as Bayesian Optimization can become rather costly due to the strategy of determining the next point of query based on the prior guesses. While Bayesian Optimization is more computationaly expensive than other search methods, it often requires less iterations to find the maxima/minima thus reducing the amount of times something like training a neural net is performed, reducing the overall computational cost. \n",
    "\n",
    "### Random Search\n",
    "![Random Search](https://daks2k3a4ib2z.cloudfront.net/59235ff882b78a59a72fa9bd/593477f37fa7db0d44d42510_tumblr_inline_o7181jRDUR1toi3ym_540.gif)\n",
    "\n",
    "### Grid Search\n",
    "![Grid Search](https://daks2k3a4ib2z.cloudfront.net/59235ff882b78a59a72fa9bd/593477f0c5b12e2f0b26ec3a_tumblr_inline_o7181iRIMT1toi3ym_540.gif)\n",
    "\n",
    "### Bayesian Optimization\n",
    "![Bayesian Optimization](https://daks2k3a4ib2z.cloudfront.net/59235ff882b78a59a72fa9bd/593477fa4beb0a0d64a26806_tumblr_inline_o7181mi1eT1toi3ym_540.gif)\n",
    "\n",
    "## Summarize\n",
    "- Finds min/max with relatively few evaluations\n",
    "- Cost of more computation to determine next point to try\n",
    "- Good for expensive functions such as ML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import scikit models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    boston.data, boston.target, train_size=0.9, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model to Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters to Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt.space import Integer\n",
    "from skopt.space import Categorical\n",
    "\n",
    "space = [Integer(1, 200, name='n_estimators'),\n",
    "         Categorical(('auto', 'sqrt', 'log2'), name='max_features'),\n",
    "         Integer(2, 100, name='min_samples_split'),\n",
    "         Integer(1, 100, name='min_samples_leaf')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt.utils import use_named_args\n",
    "\n",
    "\n",
    "@use_named_args(space)\n",
    "def objective(**params):\n",
    "    regr.set_params(**params)\n",
    "    regr.fit(X_train, y_train)\n",
    "\n",
    "    return mean_absolute_error(y_test, regr.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import gp_minimize\n",
    "\n",
    "res_gp = gp_minimize(objective, space, n_calls=20, random_state=0)\n",
    "\n",
    "res_gp.fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_gp.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = res_gp.x[0]\n",
    "max_features = res_gp.x[1]\n",
    "min_samples_split = res_gp.x[2]\n",
    "min_samples_leaf = res_gp.x[3]\n",
    "\n",
    "regr = RandomForestRegressor(n_jobs=-1, n_estimators=n_estimators, max_features=max_features,\n",
    "                             min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf)\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "predicted = regr.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, predicted)\n",
    "mse = mean_squared_error(y_test, predicted)\n",
    "rmse = sqrt(mse)\n",
    "print('MAE:', mae, '\\tMSE:', mse, '\\tRMSE:', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_size = ('%0.1f' % (100 - (len(y_test)/len(boston.target) * 100)))\n",
    "class_type = str(regr).split('(')[0]\n",
    "label1 = ('MAE   = {}'.format('%8.3f' % mae))\n",
    "label2 = (class_type + '\\nTraining size = ' + training_size + '%')\n",
    "\n",
    "plt.figure(dpi=250)\n",
    "plt.plot([min(boston.target), max(boston.target)], [\n",
    "         min(boston.target), max(boston.target)], ls=\"--\", c=\"g\")\n",
    "plt.plot(y_test, predicted, 'o', markersize=1.5)\n",
    "plt.xlabel(\"Actual Price\")\n",
    "plt.ylabel(\"Predicted Price\")\n",
    "legend1 = plt.legend([label1], loc='lower right',\n",
    "                     markerscale=0, fontsize=6, handlelength=0)\n",
    "plt.legend([label2], loc='upper left',\n",
    "           markerscale=0, fontsize=6, handlelength=0)\n",
    "plt.gca().add_artist(legend1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What to do now? \n",
    "- Try a different classifier/regressor\n",
    "- Try with a different dataset provided by scikit-learn\n",
    "- Try out a different library"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
